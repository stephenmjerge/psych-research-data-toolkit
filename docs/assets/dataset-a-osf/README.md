# Dataset A — OSF Bundle Staging

Use this folder to collect the files that will be uploaded to OSF once Dataset A clears review. Nothing here contains PHI; everything is generated by `scripts/run_dataset_a.sh` using the vetted `configs/dataset_a.toml` profile.

## Folder Layout

```
docs/assets/dataset-a-osf/
├── README.md                # This playbook
├── bundle/                  # Holds the zipped upload + README handed to OSF
│   └── .gitkeep             # Replace with dataset-a-osf-bundle.zip once built
└── provenance/              # Run manifests + config snapshots for auditors
    └── .gitkeep
```

When the pipeline finishes, copy the sanitized outputs (CSV, JSON, PNG) into a staging folder, zip them, and drop the archive inside `bundle/` (example name: `dataset-a-osf-bundle-20251114.zip`). Keep the unzipped directory locally until the OSF upload is confirmed.

## Re-run the Dataset A Pipeline

1. Export the anonymization key (or load it from your secrets manager):
   ```bash
   export PRDT_ANON_KEY="$(openssl rand -hex 32)"
   ```
2. Point the helper script at the encrypted CSV and where you want the outputs to land. Never set `ALLOW_PHI_EXPORT` for production runs.
   ```bash
   DATASET_A_INPUT="/secure/raw/dataset_a.csv" \
   DATASET_A_OUTDIR="$(pwd)/outputs/dataset-a-osf" \
   scripts/run_dataset_a.sh
   ```
3. Inspect the resulting directory:
   - `interim_clean.csv`, `alerts.json`, `report.json`, plots → move into the OSF staging folder.
   - `phi_quarantine.csv` → verify, then keep private (do **not** upload to OSF).
   - `run_manifest_*.json` → copy into `provenance/` so the OSF README can cite the exact run.
4. Zip only the shareable artifacts and place the archive in `bundle/` alongside a short `OSF_README.md` that summarizes the contents.

## Upload Checklist

- [ ] Confirm `scripts/run_dataset_a.sh` completed without errors.
- [ ] Copy the latest `configs/dataset_a.toml` and `run_manifest_*.json` into `provenance/`.
- [ ] Rename the archive to include the run date (`dataset-a-osf-bundle-YYYYMMDD.zip`).
- [ ] Update `docs/dataset_a.md`, `README.md`, and `docs/PortfolioHub.md` with the OSF link + rerun instructions.
- [ ] Record the upload date + DOI in `meta/launchpad/next-actions.md` before moving to the next repo.
